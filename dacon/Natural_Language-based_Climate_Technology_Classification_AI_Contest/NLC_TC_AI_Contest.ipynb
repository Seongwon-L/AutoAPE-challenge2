{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_test.ipynb","provenance":[],"machine_shape":"hm","mount_file_id":"196DZvGyVVXfwIqSmPYKOnDEWG4r7O_5R","authorship_tag":"ABX9TyOS1a8/gVeAr7L3DcoK6VZB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"AoOLjWmplVY7"},"source":["!pip install --upgrade pip\n","!pip install konlpy  \n","\n","!pip install nltk"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W0DEvVc7lXN5","executionInfo":{"status":"ok","timestamp":1633567267549,"user_tz":-540,"elapsed":304,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"cbf054e3-96b8-4726-ab2a-1c360bae602f"},"source":["import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords  \n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import re\n","import json\n","import os\n","from tqdm import tqdm, tqdm_pandas\n","\n","from konlpy.tag import Okt\n","from konlpy.tag import Mecab\n","\n","import sklearn\n","from sklearn.preprocessing import LabelEncoder\n","\n","from sklearn.metrics import log_loss, accuracy_score,f1_score\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","from collections import Counter\n","\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"nykBqqrKlY_r"},"source":["train=pd.read_csv('train.csv')\n","test=pd.read_csv('test.csv')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qGPoZy7jlcfb"},"source":["train.fillna('NoContent', inplace=True)\n","test.fillna('NoContent', inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QSpxtxN1leJJ","executionInfo":{"status":"ok","timestamp":1633566436671,"user_tz":-540,"elapsed":6596,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}}},"source":["okt = Okt()\n","def trans_token(text):\n","  text = re.sub('가\\.',' ',str(text))\n","  text = re.sub('나\\.',' ',text)\n","  # text = re.sub('-\\d+','num', text)\n","  text = re.sub('\\<br\\>',' ',text)\n","  text = re.sub('[\\*\\n]',' ',text)\n","  text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z\\- ]\",\" \", text)\n","  text = text.lower()\n","  if len(text) == 0:\n","    return ['NoContent']\n","  return okt.pos(text)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BEsm9Mb9lfFS","executionInfo":{"status":"ok","timestamp":1632449730424,"user_tz":-540,"elapsed":3825,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"f2b2eaba-ad86-49b5-b06d-54ba5fe8fe61"},"source":["# 키워드는 대부분 품사가 명사임\n","tokens = okt.pos(train['과제명'].loc[0])\n","only_noun = [ x[0] for x in tokens if x[1] == 'Noun']\n","print(train['과제명'].loc[0])\n","print(only_noun)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["유전정보를 활용한 새로운 해충 분류군 동정기술 개발\n","['유전', '정보', '활용', '해충', '분류군', '동정', '기술', '개발']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"453iUEUMlfz1","executionInfo":{"status":"ok","timestamp":1632449730426,"user_tz":-540,"elapsed":13,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"557592ff-11e2-49b9-8bfc-d876fe72056f"},"source":["# 띄어쓰기와 전문용어가 많은 데이터 특성상 \n","\n","tokens = okt.pos(train['과제명'].loc[21])\n","only_noun = [ x[0] for x in tokens if x[1] in ['Noun', 'Alpha']]\n","print(train['과제명'].loc[21])\n","print(only_noun)\n","print(okt.pos(train['과제명'].loc[21]))\n","# 띄어쓰기 문제로 한 단어가 Modifier(수식언,관형사)로 잘못 분리, 구조물 -> 구 + 조물"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["수지함침공정을 이용한 항공기 날개구조물 고굴곡 스파 개발\n","['함침', '공정', '이용', '항공기', '날개', '조물', '굴곡', '스파', '개발']\n","[('수', 'Modifier'), ('지', 'Modifier'), ('함침', 'Noun'), ('공정', 'Noun'), ('을', 'Josa'), ('이용', 'Noun'), ('한', 'Josa'), ('항공기', 'Noun'), ('날개', 'Noun'), ('구', 'Modifier'), ('조물', 'Noun'), ('고', 'Modifier'), ('굴곡', 'Noun'), ('스파', 'Noun'), ('개발', 'Noun')]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_uO8wQialgvd","executionInfo":{"status":"ok","timestamp":1632449747765,"user_tz":-540,"elapsed":297,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"3cae3d5f-d624-4b7a-8533-02a5ce59f6ec"},"source":["tokens = okt.pos(train['과제명'].loc[1])\n","only_noun = [ x[0] for x in tokens if x[1] in ['Noun', 'Alpha']]\n","print(train['과제명'].loc[1])\n","print(only_noun)\n","print(okt.pos(train['과제명'].loc[1]))\n","# 잘못된 Determiner(관형사) 분리로 내성이라는 고유의 의미를 갖는 명사가 내, 성으로 쪼개짐 "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축에 관한 연구\n","['대장암', 'TRAIL', '성', '표적', '인자', '발굴', '및', 'TRAIL', '반응', '예측', '유전자', '지도', '구축', '관', '연구']\n","[('대장암', 'Noun'), ('의', 'Josa'), ('TRAIL', 'Alpha'), ('내', 'Determiner'), ('성', 'Noun'), ('표적', 'Noun'), ('인자', 'Noun'), ('발굴', 'Noun'), ('및', 'Noun'), ('TRAIL', 'Alpha'), ('반응', 'Noun'), ('예측', 'Noun'), ('유전자', 'Noun'), ('지도', 'Noun'), ('구축', 'Noun'), ('에', 'Josa'), ('관', 'Noun'), ('한', 'Josa'), ('연구', 'Noun')]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SzAwIuN1llWa","executionInfo":{"status":"ok","timestamp":1632449750923,"user_tz":-540,"elapsed":444,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"84687df2-399c-4023-d4b8-dff5c89cac12"},"source":["tokens = okt.pos(train['요약문_연구목표'].loc[13])\n","only_noun = [ x[0] for x in tokens if x[1] in ['Noun', 'Alpha']]\n","print(train['요약문_연구목표'].loc[13][140:180])\n","print(only_noun[30:40])\n","print(okt.pos(train['요약문_연구목표'].loc[13][140:175]))\n","# Modifier(수식언,관형사), Suffix(접미사) 잘못 분리/ 전자구조-> 전 + 자구 + 조"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" 촉매반응 과정 중에 일어나는 표면 전자구조변위의 동역학연구를 진행하고자\n","['촉매', '반응', '과정', '중', '표면', '자구', '변위', '동역학', '연구', '진행']\n","[('촉매', 'Noun'), ('반응', 'Noun'), ('과정', 'Noun'), ('중', 'Noun'), ('에', 'Josa'), ('일어나는', 'Verb'), ('표면', 'Noun'), ('전', 'Modifier'), ('자구', 'Noun'), ('조', 'Suffix'), ('변위', 'Noun'), ('의', 'Josa'), ('동역학', 'Noun'), ('연구', 'Noun'), ('를', 'Josa')]\n"]}]},{"cell_type":"code","metadata":{"id":"aVNnKUxSlmP3","executionInfo":{"status":"ok","timestamp":1633566147842,"user_tz":-540,"elapsed":758,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}}},"source":["kor_stop_words = ['후', '재', '통해', '통한','적','트','급','함','그','대한','은','상','인','무','피',\n","                  '용','활용','급','을','를','것','것임','임','기반','통한','별','때','외','못','기','년',\n","                  '차','간','등', '이','내','또','중','다른','역','일','제','통','시','총','상의','법','로',\n","                  '이들','물','개','년','건','주','사','점','계','각','더','뿐','안','두','유','과','와','덜',\n","                  '회','전','약','바','즉','신','데','좀','더','리','몇','최','번','움','줌','음','샤','셔',\n","                  '그것','형',\n","                  ]\n","custom_stop_words = ['주요','목표','개선','향상','과제','개발','기술','연구','선행','시스템','다음','매우','이용','로서','기존',\n","                     '극복','장점','단점','문제','문제점','각각','관련','부분','간의','이상','달성','주된내용','내용','국내',\n","                     '해외','최종','사용','효과','기관','제공','이하','목적','년차','필요','때문','로부터','최종적','만개','크게',\n","                     '모두','의미','여러','하나로','중심','한번','창','실','베','헤','핑','메','위해','차년','년도']\n","\n","noun_char_to_front = ['러닝','품','체','층','능','브','스','물','팅','이드','버','리움','링','터','레이','베이','막','단','산',\n","                      '신','량','사체','액','망','켓','션','텍','틴','셋','론']\n","\n","kor_stop_words = kor_stop_words + custom_stop_words\n","eng_stop_words = list(set(stopwords.words('english') + ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']))\n","stop_words = kor_stop_words + eng_stop_words\n","\n","Modifier_to_front = ['칠','귀','속','별','너','두','흔','울','댓','성']\n","Modifier_no_change = ['동','총','순','양대', '일대','전전','다른','닷']\n","Modifier_to_Noun = ['암','즉석','기만','수조','온간','수삼']\n","\n","\n","def fixed_okt_tokenizer(text):\n","\n","  tuple_tokens = text\n","  list_tokens = []\n","  for i in tuple_tokens:\n","    list_tokens.append(list(i))\n","  for i in range(len(list_tokens)):\n","\n","    #보편적으로 작업해줘야하는 것\n","    if i < len(list_tokens) - 1:\n","\n","      if (list_tokens[i+1][1] == 'Modifier') and (list_tokens[i+1][0] in Modifier_to_front):\n","        list_tokens[i][0] = list_tokens[i][0] + list_tokens[i+1][0]\n","        list_tokens[i][1] = 'Noun'\n","        list_tokens[i+1][1] = '제외'\n","        continue\n","\n","      elif (list_tokens[i][1] == 'Modifier') and (list_tokens[i][0] not in (Modifier_to_front + Modifier_no_change + Modifier_to_Noun)):\n","        if (list_tokens[i][0] == '양') and (list_tokens[i-1][0] == '요' and list_tokens[i-1][1] == 'Josa'):\n","          list_tokens[i-1][0] = list_tokens[i-1][0] + list_tokens[i][0]\n","          list_tokens[i-1][1] = 'Noun'\n","          continue\n","\n","        list_tokens[i+1][0] = list_tokens[i][0] + list_tokens[i+1][0]\n","        list_tokens[i+1][1] = 'Noun'\n","  \n","        continue\n","\n","      elif (list_tokens[i][1] == 'Suffix') and (list_tokens[i][0] == '분') and list_tokens[i+1][0][0] in ['리','류','석']:\n","        list_tokens[i+1][0] = list_tokens[i][0] + list_tokens[i+1][0]\n","        list_tokens[i+1][1] = 'Noun'\n","        continue\n","\n","      elif (list_tokens[i][1] == 'Determiner') and (list_tokens[i+1][1] == 'Noun'):\n","        list_tokens[i+1][0] = list_tokens[i][0] + list_tokens[i+1][0]\n","        list_tokens[i][1] = '제외'\n","        continue\n","\n","      elif (list_tokens[i][0] in ['위','관'] and (list_tokens[i][1] == 'Noun')) and ((list_tokens[i+1][1] == 'Verb') or (list_tokens[i+1][1] == 'Josa')): # 위하여, 위한, 위해서는, 관하여, 관한, 관해서는 등 제거\n","        list_tokens[i][1] = '제외'\n","        continue\n","\n","      elif ((list_tokens[i][0] == '및' or (list_tokens[i][0] == '의')) and (list_tokens[i][1] == 'Noun')): # 및 제거\n","        list_tokens[i][1] = '제외'\n","        continue\n","\n","      elif (list_tokens[i][0] == ('초') and (list_tokens[i][1] == 'Noun')) and (list_tokens[i+1][1] == 'Noun'):\n","        list_tokens[i+1][0] = list_tokens[i][0] + list_tokens[i+1][0]\n","        list_tokens[i][1] = '제외'\n","        continue\n","\n","      elif (list_tokens[i][0] in ['퇴','초','비','산'] and (list_tokens[i][1] == 'Noun')):\n","        if (list_tokens[i][0] == '산') and (list_tokens[i+1][0] != '업체'):\n","          continue \n","        list_tokens[i][1] = '제외'\n","        list_tokens[i+1][0] = list_tokens[i][0] + list_tokens[i+1][0]\n","        # list_tokens[i+1][1] = 'Noun'\n","        continue\n","\n","      elif (list_tokens[i][0] == '검' and (list_tokens[i][1] == 'Noun')):\n","        list_tokens[i][1] = '제외'\n","        list_tokens[i+1][1] = 'Noun'\n","        if list_tokens[i+1][0][0] == '출':\n","          list_tokens[i+1][0] = '검출'\n","          continue\n","        list_tokens[i+1][0] = list_tokens[i][0] + list_tokens[i+1][0]\n","        continue\n","      \n","      elif (list_tokens[i][0] == '변' and list_tokens[i][1] == 'Noun') and (list_tokens[i+1][0][0] == '이'):\n","        list_tokens[i][1] = '제외'\n","        list_tokens[i+1][0] = '변이'\n","        list_tokens[i+1][1] = 'Noun'\n","        continue\n","\n","      elif (list_tokens[i][0] == '실' and list_tokens[i][1] == 'Noun') and (list_tokens[i+1][0][0] == '내'):\n","        list_tokens[i][1] = '제외'\n","        list_tokens[i+1][0] = list_tokens[i][0] + list_tokens[i+1][0]\n","        continue\n","\n","      elif (list_tokens[i][0] == '할' and (list_tokens[i][1] == 'Verb')) and (list_tokens[i+1][0] == '수' and (list_tokens[i+1][1] == 'Noun')):\n","        list_tokens[i+1][1] = '제외'\n","\n","\n","\n","    if (list_tokens[i][1] == 'Modifier') and (list_tokens[i][0] in Modifier_no_change):\n","      continue\n","\n","    elif (list_tokens[i][1] == 'Modifier') and (list_tokens[i][0] in Modifier_to_Noun):\n","      list_tokens[i][1] = 'Noun'\n","\n","    elif (list_tokens[i][1] == 'Suffix') or ((list_tokens[i][0] == '학') or (list_tokens[i][0] == '율') or (list_tokens[i][0] == '률')):\n","      if (list_tokens[i][0] in ['들']):\n","        continue\n","      list_tokens[i][0] = list_tokens[i-1][0] + list_tokens[i][0]\n","      list_tokens[i][1] = 'Noun'\n","      list_tokens[i-1][1] = 'Josa'\n","      \n","      \n","    #뒷 글자를 앞에 붙일 때 \n","    elif (list_tokens[i][0] == ('기후학') and (list_tokens[i][1] == 'Noun')) and (list_tokens[i-1][0] == ('법') and (list_tokens[i-1][1] == 'Noun')):\n","      list_tokens[i-1][0] = list_tokens[i-1][0] + list_tokens[i][0]\n","      list_tokens[i][1] = 'JOSA'\n","\n","    elif (list_tokens[i][0] in noun_char_to_front) and (list_tokens[i][1] == 'Noun'):\n","      if (list_tokens[i][0] in ['물']) and (list_tokens[i-1][1] != 'Noun'):\n","        continue\n","      elif (list_tokens[i][0] == '버') and (list_tokens[i-1][0][-1] not in ['이','터']):\n","        continue\n","      elif (list_tokens[i][0] == '스') and (list_tokens[i-1][0][-1] not in ['레']):\n","        continue\n","      elif (list_tokens[i][0] == '신') and (list_tokens[i-1][0][-1] not in ['수']):\n","        continue\n","      elif (list_tokens[i][0] == '산') and (list_tokens[i-1][0] not in ['국내']):\n","        continue\n","      elif (list_tokens[i][0] == '사체') and (list_tokens[i-1][0] not in ['피전','피']):\n","        continue\n","      elif (list_tokens[i][0] == '러닝') and (list_tokens[i-1][0] not in ['딥']):\n","        continue\n","\n","      elif (list_tokens[i][0] in ['레이','베이']) and (i != 0):\n","        list_tokens[i][0] = list_tokens[i-1][0] + list_tokens[i][0]\n","        list_tokens[i-1][1] = '제외'\n","        continue\n","\n","\n","      list_tokens[i][1] = '제외'\n","      list_tokens[i-1][0] = list_tokens[i-1][0] + list_tokens[i][0]\n","      if list_tokens[i][0] in ['이드','리움','링']:\n","        list_tokens[i-1][1] = 'Noun'\n","\n","\n","    elif (list_tokens[i][0] == ('열') and (list_tokens[i][1] == 'Noun')) and (list_tokens[i-1][1] == 'Noun'):\n","      list_tokens[i-1][0] = list_tokens[i-1][0] + list_tokens[i][0]\n","      list_tokens[i][1] = '제외'\n","    elif list_tokens[i][0][:2] == ('백신'):\n","      list_tokens[i][0] = '백신'\n","      list_tokens[i][1] = 'Noun' \n","    elif (i != 0) and (i != len(list_tokens) - 1) and (list_tokens[i][0] == '-'):\n","      if (list_tokens[i-1][1] == 'Alpha') and (list_tokens[i+1][1] in ['Alpha','Number']):\n","        list_tokens[i-1][1] = '제외'\n","        list_tokens[i][1] = '제외'\n","        list_tokens[i+1][1] = 'Noun'\n","        list_tokens[i+1][0] = list_tokens[i-1][0] + list_tokens[i][0] + list_tokens[i+1][0]\n","    elif ((list_tokens[i][0] == '형') and (list_tokens[i][1] == 'Noun')) and (okt.pos(list_tokens[i-1][0])[-1][1] in ['Number','Alpha']):\n","      list_tokens[i][1] = '제외'\n","      list_tokens[i-1][0] = list_tokens[i-1][0] + list_tokens[i][0]\n","        \n","\n","  tokens = []\n","  for word, tag in list_tokens : \n","      if (tag in ['Noun', 'Alpha']) and (word not in stop_words):  #명사, 알파뱃만 사용\n","          tokens.append(word)\n","  return tokens"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"5KamhTxPlorQ"},"source":["def united_contents(text):\n","  text = re.sub('\\(R&D\\)','',text)\n","  text = re.sub('\\(\\w+\\)','',text)\n","  text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z ]','',text)\n","  return [text]\n","\n","train['united_내역사업명'] = train['내역사업명'].apply(united_contents)\n","test['united_내역사업명'] = test['내역사업명'].apply(united_contents)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRBndPYdlxQj","executionInfo":{"status":"ok","timestamp":1632470650917,"user_tz":-540,"elapsed":20849417,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"cd048ff5-8e1a-4f4a-f72d-80c6112ca19b"},"source":["tqdm.pandas()\n","\n","train['token_내역사업명'] = train['united_내역사업명'].progress_apply(trans_token)\n","train['token_과제명'] = train['과제명'].progress_apply(trans_token)\n","train['token_요약문_한글키워드'] = train['요약문_한글키워드'].progress_apply(trans_token)\n","train['token_요약문_연구목표'] = train['요약문_연구목표'].progress_apply(trans_token)\n","\n","test['token_내역사업명'] = test['united_내역사업명'].progress_apply(trans_token)\n","test['token_과제명'] = test['과제명'].progress_apply(trans_token)\n","test['token_요약문_한글키워드'] = test['요약문_한글키워드'].progress_apply(trans_token)\n","test['token_요약문_연구목표'] = test['요약문_연구목표'].progress_apply(trans_token)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]\n","TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n","174304it [08:53, 327.00it/s]\n","100%|██████████| 174304/174304 [12:03<00:00, 240.87it/s]\n","100%|██████████| 174304/174304 [17:32<00:00, 165.63it/s]\n","100%|██████████| 174304/174304 [3:25:23<00:00, 14.14it/s]\n","100%|██████████| 43576/43576 [09:44<00:00, 74.60it/s]\n","100%|██████████| 43576/43576 [08:58<00:00, 80.92it/s]\n","100%|██████████| 43576/43576 [09:53<00:00, 73.46it/s]\n","100%|██████████| 43576/43576 [1:15:00<00:00,  9.68it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yj2egx7Nlytp","executionInfo":{"status":"ok","timestamp":1632470863367,"user_tz":-540,"elapsed":212462,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"ac1a856c-2b15-40d3-826b-dadd22cd7ef7"},"source":["tqdm.pandas()\n","\n","train['fixed_okt_내역사업명'] = train['token_내역사업명'].progress_apply(fixed_okt_tokenizer)\n","train['fixed_okt_과제명'] = train['token_과제명'].progress_apply(fixed_okt_tokenizer)\n","train['fixed_okt_요약문_한글키워드'] = train['token_요약문_한글키워드'].progress_apply(fixed_okt_tokenizer)\n","train['fixed_okt_요약문_연구목표'] = train['token_요약문_연구목표'].progress_apply(fixed_okt_tokenizer)\n","\n","test['fixed_okt_내역사업명'] = test['token_내역사업명'].progress_apply(fixed_okt_tokenizer)\n","test['fixed_okt_과제명'] = test['token_과제명'].progress_apply(fixed_okt_tokenizer)\n","test['fixed_okt_요약문_한글키워드'] = test['token_요약문_한글키워드'].progress_apply(fixed_okt_tokenizer)\n","test['fixed_okt_요약문_연구목표'] = test['token_요약문_연구목표'].progress_apply(fixed_okt_tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]\n","TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n","174304it [00:06, 28235.74it/s]\n","100%|██████████| 174304/174304 [00:15<00:00, 11404.32it/s]\n","100%|██████████| 174304/174304 [00:17<00:00, 9970.85it/s] \n","100%|██████████| 174304/174304 [02:10<00:00, 1335.82it/s]\n","100%|██████████| 43576/43576 [00:01<00:00, 28247.16it/s]\n","100%|██████████| 43576/43576 [00:03<00:00, 11392.34it/s]\n","100%|██████████| 43576/43576 [00:03<00:00, 11121.07it/s]\n","100%|██████████| 43576/43576 [00:33<00:00, 1294.18it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"Sozpro5Fl1gv"},"source":["train1 = train[['index','fixed_okt_내역사업명','fixed_okt_과제명','fixed_okt_요약문_한글키워드','fixed_okt_요약문_연구목표','label']]\n","test1 = test[['index','fixed_okt_내역사업명','fixed_okt_과제명','fixed_okt_요약문_한글키워드','fixed_okt_요약문_연구목표']]\n","\n","train1.to_csv('fixed_okt_train.csv',index=False)\n","test1.to_csv('fixed_test.csv',index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25X849jMiiuV","executionInfo":{"status":"ok","timestamp":1633566093362,"user_tz":-540,"elapsed":6,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"33bc0ed0-023d-4a72-d277-4e620d82bc1e"},"source":["cd drive/MyDrive/Dacon/"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Dacon\n"]}]},{"cell_type":"code","metadata":{"id":"ujIaVj0Jl2dB","executionInfo":{"status":"ok","timestamp":1633566113256,"user_tz":-540,"elapsed":8979,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}}},"source":["train=pd.read_csv('fixed_okt_train.csv')\n","test=pd.read_csv('fixed_test.csv')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"17DQpCkQl49l","executionInfo":{"status":"ok","timestamp":1633566276637,"user_tz":-540,"elapsed":24750,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}}},"source":["# csv에는 리스트로 저장했던 것들이 문자열로 바뀌어있었으므로 문자열을 다시 리스트 형태로 변환\n","def trans_to_list(text):\n","  text = re.sub(\"[\\[\\]\\' ]\", \"\", str(text))\n","  text =  text.split(',')\n","  if text == ['']:\n","    text = ['']\n","  return text\n","\n","train['fixed_okt_과제명'] = train['fixed_okt_과제명'].apply(trans_to_list)\n","train['fixed_okt_내역사업명'] = train['fixed_okt_내역사업명'].apply(trans_to_list)\n","train['fixed_okt_요약문_한글키워드'] = train['fixed_okt_요약문_한글키워드'].apply(trans_to_list)\n","train['fixed_okt_요약문_연구목표'] = train['fixed_okt_요약문_연구목표'].apply(trans_to_list)\n","\n","test['fixed_okt_과제명'] = test['fixed_okt_과제명'].apply(trans_to_list)\n","test['fixed_okt_내역사업명'] = test['fixed_okt_내역사업명'].apply(trans_to_list)\n","test['fixed_okt_요약문_한글키워드'] = test['fixed_okt_요약문_한글키워드'].apply(trans_to_list)\n","test['fixed_okt_요약문_연구목표'] = test['fixed_okt_요약문_연구목표'].apply(trans_to_list)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"YVZKs9H2l6IC"},"source":["# 더 제외하고 싶은 단어 추가 \n","\n","del_word = [\n","            '안팎','개념','역할','중심적','또한','특이적','개월','취급','변화',\n","            '고려','가량','일반적','지원','다기','관','종합적','도출','방안','검토',\n","            '산업','강화','기업','바탕','현장','조건','방법','성숙','해당과정','위해',\n","            '검토','확립','차년','진행','과정','구축','연구개발','결과물',\n","            '검증','방안','인재','분석','발굴','규명','적용','실제','거나','연구원',\n","            '운영','확보','대하','수','능력','평가','성과','발표','도록','마련','고',\n","            '따라서','대해','제시','통합적','종합적','말함','살피','최근','대두','일반',\n","            '발전','연구개발','경우','주어','기초','년간','담당','낼','대처','성의','핵심',\n","            '주목표','상위','하위','기대','시기','증대','증가','감소','고자','이바지',\n","            '이전','현재', '이번',\n","]\n","\n","def add_filter(text):\n","  return [x for x in text if x not in del_word]\n","\n","train['filter_okt_요약문_연구목표'] = train['fixed_okt_요약문_연구목표'].apply(add_filter)\n","test['filter_okt_요약문_연구목표'] = test['fixed_okt_요약문_연구목표'].apply(add_filter)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQW8H_hWl7FP"},"source":["train['vocab'] = train['fixed_okt_내역사업명'] + train['fixed_okt_과제명']  + train['fixed_okt_요약문_한글키워드'] + train['filter_okt_요약문_연구목표']\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GGVrQBFPl8Ii"},"source":["tokenizer=Tokenizer(oov_token = 'OOV')\n","\n","tokenizer.fit_on_texts(list(train['vocab']))\n","word_vocab = tokenizer.word_index\n","\n","vocab_size = len(word_vocab)+2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GYY9gZ0Rl9aJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632700735346,"user_tz":-540,"elapsed":10,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"76bb165e-7575-4657-98c4-6767325eb126"},"source":["threshold = 10\n","total_cnt = len(tokenizer.word_index) # 단어의 수\n","rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n","total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n","rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n","\n","# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n","for key, value in tokenizer.word_counts.items():\n","    total_freq = total_freq + value\n","\n","    # 단어의 등장 빈도수가 threshold보다 작으면\n","    if(value < threshold):\n","        rare_cnt = rare_cnt + 1\n","        rare_freq = rare_freq + value\n","\n","print('단어 집합(vocabulary)의 크기 :',total_cnt)\n","print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n","print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n","print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n","\n","print('예상 단어집합 크기 :',total_cnt - rare_cnt)\n","words_num = total_cnt - rare_cnt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 집합(vocabulary)의 크기 : 165958\n","등장 빈도가 9번 이하인 희귀 단어의 수: 121699\n","단어 집합에서 희귀 단어의 비율: 73.33120428060111\n","전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.6347518664728007\n","예상 단어집합 크기 : 44259\n"]}]},{"cell_type":"code","metadata":{"id":"cvS-WeMhl-pV"},"source":["# tokenizer=Tokenizer()\n","tokenizer=Tokenizer(num_words=words_num,oov_token = 'OOV')\n","\n","tokenizer.fit_on_texts(list(train['vocab']))\n","word_vocab = tokenizer.word_index\n","\n","vocab_size = len(word_vocab)+2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHh_C3GCl_gk"},"source":["train['input_0'] = train['fixed_okt_내역사업명'] + train['fixed_okt_과제명'] + train['fixed_okt_요약문_한글키워드']\n","train['input_1'] = train['filter_okt_요약문_연구목표']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JGSkZTDEmALr"},"source":["test['input_0'] = test['fixed_okt_내역사업명'] + test['fixed_okt_과제명'] + test['fixed_okt_요약문_한글키워드']\n","test['input_1'] = test['filter_okt_요약문_연구목표']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MV46w1FEmA9s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632700747376,"user_tz":-540,"elapsed":6,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"26c57a7c-f769-4516-f305-bec67615a82a"},"source":["train_length = train['input_0'].apply(len)\n","train_length.head()\n","\n","# 사분위의 대한 경우는 0~100 스케일로 되어있음\n","print('인풋 길이 제 1 사분위: {}'.format(np.percentile(train_length, 25)))\n","print('인풋 길이 제 3 사분위: {}'.format(np.percentile(train_length, 75)))\n","\n","number = 98\n","print('인풋 길이 {}%: {}'.format(number,np.percentile(train_length, number)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["인풋 길이 제 1 사분위: 17.0\n","인풋 길이 제 3 사분위: 25.0\n","인풋 길이 98%: 35.0\n"]}]},{"cell_type":"code","metadata":{"id":"EDshYn7omCD8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632700747377,"user_tz":-540,"elapsed":6,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"43f0e143-b98a-475e-aaa8-6f1abf711ab8"},"source":["train_length = train['input_1'].apply(len)\n","train_length.head()\n","\n","# 사분위의 대한 경우는 0~100 스케일로 되어있음\n","print('인풋 길이 제 1 사분위: {}'.format(np.percentile(train_length, 25)))\n","print('인풋 길이 제 3 사분위: {}'.format(np.percentile(train_length, 75)))\n","\n","number = 98\n","print('인풋 길이 {}%: {}'.format(number,np.percentile(train_length, number)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["인풋 길이 제 1 사분위: 23.0\n","인풋 길이 제 3 사분위: 68.0\n","인풋 길이 98%: 170.0\n"]}]},{"cell_type":"code","metadata":{"id":"VS6VXMJUmC7s"},"source":["# 0이 아닌 데이터 2번 복사하여 추가, 추가로 오답률이 높은 label 2번 복사하여 추가 \n","temp = train.copy()\n","temp1 = temp[temp['label'] != 0]\n","temp2 = temp[(temp['label'] == 11)|(temp['label'] == 12)|(temp['label'] == 13)|(temp['label'] == 17)|(temp['label'] == 20)|(temp['label'] == 23)|(temp['label'] == 25)|(temp['label'] == 26)|(temp['label'] == 37)|(temp['label'] == 38)]\n","\n","temp = pd.concat([temp, temp1], axis = 0).reset_index(drop = True)\n","temp = pd.concat([temp, temp1], axis = 0).reset_index(drop = True)\n","temp = pd.concat([temp, temp2], axis = 0).reset_index(drop = True)\n","temp = pd.concat([temp, temp2], axis = 0).reset_index(drop = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJFpDfBxmD5f"},"source":["max_len = [35, 170]\n","\n","\n","# train_encoded_0 = tokenizer.texts_to_sequences(list(train['input_0']))\n","train_encoded_0 = tokenizer.texts_to_sequences(list(temp['input_0']))\n","train_input_0 = pad_sequences(train_encoded_0, maxlen=max_len[0], padding='post')\n","\n","# train_encoded_1 = tokenizer.texts_to_sequences(list(train['input_1']))\n","train_encoded_1 = tokenizer.texts_to_sequences(list(temp['input_1']))\n","train_input_1 = pad_sequences(train_encoded_1, maxlen=max_len[1], padding='post')\n","\n","train_input_0 = tf.convert_to_tensor(train_input_0, dtype=tf.float32)\n","train_input_1 = tf.convert_to_tensor(train_input_1, dtype=tf.float32)\n","\n","train_input = []\n","train_input.append(train_input_0)\n","train_input.append(train_input_1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EFPJ-3MXmFDa"},"source":["test_encoded_0 = tokenizer.texts_to_sequences(list(test['input_0']))\n","test_input_0 = pad_sequences(test_encoded_0, maxlen=max_len[0], padding='post')\n","\n","test_encoded_1 = tokenizer.texts_to_sequences(list(test['input_1']))\n","test_input_1 = pad_sequences(test_encoded_1, maxlen=max_len[1], padding='post')\n","\n","test_input_0 = tf.convert_to_tensor(test_input_0, dtype=tf.float32)\n","test_input_1 = tf.convert_to_tensor(test_input_1, dtype=tf.float32)\n","\n","test_input = []\n","test_input.append(test_input_0)\n","test_input.append(test_input_1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKVuE3mZmF_z"},"source":["def trans_label(number):\n","    vector =  np.array([0] * 46)\n","    vector[number] = 1\n","    return vector\n","\n","# train['label_vector'] = train['label'].apply(trans_label)\n","# labels = tf.convert_to_tensor(list(train['label_vector']), dtype=tf.float32)\n","\n","temp['label_vector'] = temp['label'].apply(trans_label)\n","labels = tf.convert_to_tensor(list(temp['label_vector']), dtype=tf.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCcHEylYmG2E"},"source":["embedding_dim = [512, 512]\n","\n","def convolutional_model(embedding_dim = embedding_dim, max_len = max_len, num_labels = 46):\n","    \n","    train_input_0 = tf.keras.Input(shape=(max_len[0],))\n","    train_input_1 = tf.keras.Input(shape=(max_len[1],))\n","\n","\n","    x0 = tf.keras.layers.Embedding(vocab_size, embedding_dim[0], input_length=max_len[0], mask_zero=True)(train_input_0)\n","    x0 = tf.keras.layers.Dropout(0.2)(x0)\n","\n","    x0 = tf.keras.layers.Conv1D(embedding_dim[0], kernel_size=3, padding='valid', activation=None)(x0)\n","    x0 = tf.keras.layers.BatchNormalization()(x0)\n","    x0 = tf.keras.layers.Activation('relu')(x0)\n","    x0 = tf.keras.layers.Dropout(0.2)(x0)\n","    x0 = tf.keras.layers.GlobalMaxPooling1D()(x0)\n","\n","    x0 = tf.keras.layers.Dense(128, activation=None)(x0)\n","    x0 = tf.keras.layers.BatchNormalization()(x0)\n","    x0 = tf.keras.layers.Activation('relu')(x0)\n","    x0 = tf.keras.layers.Dropout(0.2)(x0)\n","\n","\n","    x1 = tf.keras.layers.Embedding(vocab_size, embedding_dim[1], input_length=max_len[1], mask_zero=True)(train_input_1)\n","    x1 = tf.keras.layers.Dropout(0.2)(x1)\n","    \n","    x1 = tf.keras.layers.Conv1D(embedding_dim[1], kernel_size=3, padding='valid', activation='relu')(x1)\n","    x1 = tf.keras.layers.BatchNormalization()(x1)\n","    x1 = tf.keras.layers.Activation('relu')(x1)\n","    x1 = tf.keras.layers.Dropout(0.2)(x1)\n","    x1 = tf.keras.layers.GlobalMaxPooling1D()(x1)\n","\n","    x1 = tf.keras.layers.Dense(128, activation=None)(x1)\n","    x1 = tf.keras.layers.BatchNormalization()(x1)\n","    x1 = tf.keras.layers.Activation('relu')(x1)\n","    x1 = tf.keras.layers.Dropout(0.2)(x1)\n","\n","\n","    fc = tf.keras.layers.Concatenate()([x0,x1])\n","\n","    fc = tf.keras.layers.Dense(128, activation=None)(fc)\n","    fc = tf.keras.layers.BatchNormalization()(fc)\n","    fc = tf.keras.layers.Activation('relu')(fc)\n","    fc = tf.keras.layers.Dropout(0.2)(fc)\n","\n","    labels = tf.keras.layers.Dense(num_labels, activation = 'softmax')(fc)\n","    \n","    model = tf.keras.Model([train_input_0,train_input_1], labels)\n","    optimizer = tf.keras.optimizers.Adam()\n","    model.compile(optimizer = optimizer, loss = 'CategoricalCrossentropy', metrics = ['accuracy'])\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"20SjAUudmIFC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632723553676,"user_tz":-540,"elapsed":22782927,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"a056a7b1-0a7f-4247-8194-2e05919bd146"},"source":["es = EarlyStopping(monitor = 'val_accuracy', mode = 'max', verbose = 1, patience = 15)\n","mc = ModelCheckpoint('best_model.h5', monitor = 'val_accuracy', mode = 'max', verbose = 1, save_best_only = True)\n","\n","model = convolutional_model()\n","\n","\n","num_epochs = 60\n","\n","history = model.fit(train_input, labels, epochs=num_epochs, batch_size=4096, verbose=1, validation_split=0.2, callbacks=[es, mc])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","49/49 [==============================] - 391s 8s/step - loss: 2.0406 - accuracy: 0.6155 - val_loss: 3.8475 - val_accuracy: 0.0000e+00\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.00000, saving model to best_model.h5\n","Epoch 2/60\n","49/49 [==============================] - 388s 8s/step - loss: 0.5362 - accuracy: 0.8937 - val_loss: 4.6763 - val_accuracy: 0.0000e+00\n","\n","Epoch 00002: val_accuracy did not improve from 0.00000\n","Epoch 3/60\n","49/49 [==============================] - 386s 8s/step - loss: 0.2483 - accuracy: 0.9451 - val_loss: 5.8437 - val_accuracy: 0.0000e+00\n","\n","Epoch 00003: val_accuracy did not improve from 0.00000\n","Epoch 4/60\n","49/49 [==============================] - 386s 8s/step - loss: 0.1433 - accuracy: 0.9684 - val_loss: 6.6220 - val_accuracy: 0.0000e+00\n","\n","Epoch 00004: val_accuracy did not improve from 0.00000\n","Epoch 5/60\n","49/49 [==============================] - 388s 8s/step - loss: 0.0976 - accuracy: 0.9785 - val_loss: 7.3037 - val_accuracy: 0.0000e+00\n","\n","Epoch 00005: val_accuracy did not improve from 0.00000\n","Epoch 6/60\n","49/49 [==============================] - 385s 8s/step - loss: 0.0735 - accuracy: 0.9835 - val_loss: 7.2687 - val_accuracy: 0.0000e+00\n","\n","Epoch 00006: val_accuracy did not improve from 0.00000\n","Epoch 7/60\n","49/49 [==============================] - 385s 8s/step - loss: 0.0613 - accuracy: 0.9859 - val_loss: 7.4088 - val_accuracy: 0.0000e+00\n","\n","Epoch 00007: val_accuracy did not improve from 0.00000\n","Epoch 8/60\n","49/49 [==============================] - 387s 8s/step - loss: 0.0512 - accuracy: 0.9881 - val_loss: 6.2005 - val_accuracy: 1.4041e-04\n","\n","Epoch 00008: val_accuracy improved from 0.00000 to 0.00014, saving model to best_model.h5\n","Epoch 9/60\n","49/49 [==============================] - 387s 8s/step - loss: 0.0445 - accuracy: 0.9897 - val_loss: 5.3871 - val_accuracy: 0.0078\n","\n","Epoch 00009: val_accuracy improved from 0.00014 to 0.00782, saving model to best_model.h5\n","Epoch 10/60\n","49/49 [==============================] - 388s 8s/step - loss: 0.0403 - accuracy: 0.9901 - val_loss: 3.3079 - val_accuracy: 0.0799\n","\n","Epoch 00010: val_accuracy improved from 0.00782 to 0.07993, saving model to best_model.h5\n","Epoch 11/60\n","49/49 [==============================] - 386s 8s/step - loss: 0.0359 - accuracy: 0.9911 - val_loss: 2.0952 - val_accuracy: 0.2359\n","\n","Epoch 00011: val_accuracy improved from 0.07993 to 0.23593, saving model to best_model.h5\n","Epoch 12/60\n","49/49 [==============================] - 387s 8s/step - loss: 0.0327 - accuracy: 0.9917 - val_loss: 0.9008 - val_accuracy: 0.6170\n","\n","Epoch 00012: val_accuracy improved from 0.23593 to 0.61702, saving model to best_model.h5\n","Epoch 13/60\n","49/49 [==============================] - 391s 8s/step - loss: 0.0305 - accuracy: 0.9920 - val_loss: 0.3256 - val_accuracy: 0.8903\n","\n","Epoch 00013: val_accuracy improved from 0.61702 to 0.89028, saving model to best_model.h5\n","Epoch 14/60\n","49/49 [==============================] - 389s 8s/step - loss: 0.0276 - accuracy: 0.9928 - val_loss: 0.1665 - val_accuracy: 0.9496\n","\n","Epoch 00014: val_accuracy improved from 0.89028 to 0.94961, saving model to best_model.h5\n","Epoch 15/60\n","49/49 [==============================] - 392s 8s/step - loss: 0.0258 - accuracy: 0.9929 - val_loss: 0.1063 - val_accuracy: 0.9678\n","\n","Epoch 00015: val_accuracy improved from 0.94961 to 0.96777, saving model to best_model.h5\n","Epoch 16/60\n","49/49 [==============================] - 397s 8s/step - loss: 0.0253 - accuracy: 0.9930 - val_loss: 0.0535 - val_accuracy: 0.9802\n","\n","Epoch 00016: val_accuracy improved from 0.96777 to 0.98024, saving model to best_model.h5\n","Epoch 17/60\n","49/49 [==============================] - 398s 8s/step - loss: 0.0233 - accuracy: 0.9935 - val_loss: 0.0437 - val_accuracy: 0.9845\n","\n","Epoch 00017: val_accuracy improved from 0.98024 to 0.98447, saving model to best_model.h5\n","Epoch 18/60\n","49/49 [==============================] - 401s 8s/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.0520 - val_accuracy: 0.9807\n","\n","Epoch 00018: val_accuracy did not improve from 0.98447\n","Epoch 19/60\n","49/49 [==============================] - 400s 8s/step - loss: 0.0212 - accuracy: 0.9936 - val_loss: 0.0318 - val_accuracy: 0.9878\n","\n","Epoch 00019: val_accuracy improved from 0.98447 to 0.98780, saving model to best_model.h5\n","Epoch 20/60\n","49/49 [==============================] - 406s 8s/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.0304 - val_accuracy: 0.9891\n","\n","Epoch 00020: val_accuracy improved from 0.98780 to 0.98907, saving model to best_model.h5\n","Epoch 21/60\n","49/49 [==============================] - 406s 8s/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.0313 - val_accuracy: 0.9877\n","\n","Epoch 00021: val_accuracy did not improve from 0.98907\n","Epoch 22/60\n","49/49 [==============================] - 408s 8s/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.0306 - val_accuracy: 0.9878\n","\n","Epoch 00022: val_accuracy did not improve from 0.98907\n","Epoch 23/60\n","49/49 [==============================] - 406s 8s/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0300 - val_accuracy: 0.9875\n","\n","Epoch 00023: val_accuracy did not improve from 0.98907\n","Epoch 24/60\n","49/49 [==============================] - 409s 8s/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.0282 - val_accuracy: 0.9891\n","\n","Epoch 00024: val_accuracy improved from 0.98907 to 0.98911, saving model to best_model.h5\n","Epoch 25/60\n","49/49 [==============================] - 410s 8s/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.0276 - val_accuracy: 0.9902\n","\n","Epoch 00025: val_accuracy improved from 0.98911 to 0.99017, saving model to best_model.h5\n","Epoch 26/60\n","49/49 [==============================] - 412s 8s/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.0229 - val_accuracy: 0.9917\n","\n","Epoch 00026: val_accuracy improved from 0.99017 to 0.99174, saving model to best_model.h5\n","Epoch 27/60\n","49/49 [==============================] - 413s 8s/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.0332 - val_accuracy: 0.9868\n","\n","Epoch 00027: val_accuracy did not improve from 0.99174\n","Epoch 28/60\n","49/49 [==============================] - 410s 8s/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.0256 - val_accuracy: 0.9891\n","\n","Epoch 00028: val_accuracy did not improve from 0.99174\n","Epoch 29/60\n","49/49 [==============================] - 408s 8s/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.0267 - val_accuracy: 0.9889\n","\n","Epoch 00029: val_accuracy did not improve from 0.99174\n","Epoch 30/60\n","49/49 [==============================] - 410s 8s/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0269 - val_accuracy: 0.9895\n","\n","Epoch 00030: val_accuracy did not improve from 0.99174\n","Epoch 31/60\n","49/49 [==============================] - 409s 8s/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.0242 - val_accuracy: 0.9904\n","\n","Epoch 00031: val_accuracy did not improve from 0.99174\n","Epoch 32/60\n","49/49 [==============================] - 412s 8s/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.0261 - val_accuracy: 0.9897\n","\n","Epoch 00032: val_accuracy did not improve from 0.99174\n","Epoch 33/60\n","49/49 [==============================] - 410s 8s/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.0274 - val_accuracy: 0.9880\n","\n","Epoch 00033: val_accuracy did not improve from 0.99174\n","Epoch 34/60\n","49/49 [==============================] - 409s 8s/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.0235 - val_accuracy: 0.9900\n","\n","Epoch 00034: val_accuracy did not improve from 0.99174\n","Epoch 35/60\n","49/49 [==============================] - 411s 8s/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.0277 - val_accuracy: 0.9887\n","\n","Epoch 00035: val_accuracy did not improve from 0.99174\n","Epoch 36/60\n","49/49 [==============================] - 412s 8s/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.0236 - val_accuracy: 0.9912\n","\n","Epoch 00036: val_accuracy did not improve from 0.99174\n","Epoch 37/60\n","49/49 [==============================] - 411s 8s/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.0245 - val_accuracy: 0.9903\n","\n","Epoch 00037: val_accuracy did not improve from 0.99174\n","Epoch 38/60\n","49/49 [==============================] - 412s 8s/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.0260 - val_accuracy: 0.9892\n","\n","Epoch 00038: val_accuracy did not improve from 0.99174\n","Epoch 39/60\n","49/49 [==============================] - 411s 8s/step - loss: 0.0138 - accuracy: 0.9950 - val_loss: 0.0241 - val_accuracy: 0.9902\n","\n","Epoch 00039: val_accuracy did not improve from 0.99174\n","Epoch 40/60\n","49/49 [==============================] - 410s 8s/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.0215 - val_accuracy: 0.9915\n","\n","Epoch 00040: val_accuracy did not improve from 0.99174\n","Epoch 41/60\n","49/49 [==============================] - 410s 8s/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.0210 - val_accuracy: 0.9922\n","\n","Epoch 00041: val_accuracy improved from 0.99174 to 0.99218, saving model to best_model.h5\n","Epoch 42/60\n","49/49 [==============================] - 412s 8s/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.0301 - val_accuracy: 0.9887\n","\n","Epoch 00042: val_accuracy did not improve from 0.99218\n","Epoch 43/60\n","49/49 [==============================] - 412s 8s/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.0249 - val_accuracy: 0.9903\n","\n","Epoch 00043: val_accuracy did not improve from 0.99218\n","Epoch 44/60\n","49/49 [==============================] - 413s 8s/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.0255 - val_accuracy: 0.9905\n","\n","Epoch 00044: val_accuracy did not improve from 0.99218\n","Epoch 45/60\n","49/49 [==============================] - 409s 8s/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.0218 - val_accuracy: 0.9917\n","\n","Epoch 00045: val_accuracy did not improve from 0.99218\n","Epoch 46/60\n","49/49 [==============================] - 411s 8s/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.0248 - val_accuracy: 0.9896\n","\n","Epoch 00046: val_accuracy did not improve from 0.99218\n","Epoch 47/60\n","49/49 [==============================] - 411s 8s/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.0291 - val_accuracy: 0.9899\n","\n","Epoch 00047: val_accuracy did not improve from 0.99218\n","Epoch 48/60\n","49/49 [==============================] - 409s 8s/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.0258 - val_accuracy: 0.9899\n","\n","Epoch 00048: val_accuracy did not improve from 0.99218\n","Epoch 49/60\n","49/49 [==============================] - 412s 8s/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.0226 - val_accuracy: 0.9911\n","\n","Epoch 00049: val_accuracy did not improve from 0.99218\n","Epoch 50/60\n","49/49 [==============================] - 411s 8s/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.0225 - val_accuracy: 0.9915\n","\n","Epoch 00050: val_accuracy did not improve from 0.99218\n","Epoch 51/60\n","49/49 [==============================] - 412s 8s/step - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0236 - val_accuracy: 0.9904\n","\n","Epoch 00051: val_accuracy did not improve from 0.99218\n","Epoch 52/60\n","49/49 [==============================] - 411s 8s/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0231 - val_accuracy: 0.9905\n","\n","Epoch 00052: val_accuracy did not improve from 0.99218\n","Epoch 53/60\n","49/49 [==============================] - 412s 8s/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.0213 - val_accuracy: 0.9910\n","\n","Epoch 00053: val_accuracy did not improve from 0.99218\n","Epoch 54/60\n","49/49 [==============================] - 412s 8s/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0202 - val_accuracy: 0.9913\n","\n","Epoch 00054: val_accuracy did not improve from 0.99218\n","Epoch 55/60\n","49/49 [==============================] - 412s 8s/step - loss: 0.0116 - accuracy: 0.9955 - val_loss: 0.0204 - val_accuracy: 0.9917\n","\n","Epoch 00055: val_accuracy did not improve from 0.99218\n","Epoch 56/60\n","49/49 [==============================] - 411s 8s/step - loss: 0.0116 - accuracy: 0.9955 - val_loss: 0.0234 - val_accuracy: 0.9900\n","\n","Epoch 00056: val_accuracy did not improve from 0.99218\n","Epoch 00056: early stopping\n"]}]},{"cell_type":"code","metadata":{"id":"l0t6KUsMmJqN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632725632134,"user_tz":-540,"elapsed":2078466,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"25abb0dc-bcae-494f-8424-89de82deb184"},"source":["num_epochs = 5\n","\n","history = model.fit(train_input, labels, epochs=num_epochs, batch_size=4096, verbose=1, validation_split=0.2, callbacks=[es, mc])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","49/49 [==============================] - 415s 8s/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0192 - val_accuracy: 0.9931\n","\n","Epoch 00001: val_accuracy improved from 0.99218 to 0.99310, saving model to best_model.h5\n","Epoch 2/5\n","49/49 [==============================] - 415s 8s/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0268 - val_accuracy: 0.9894\n","\n","Epoch 00002: val_accuracy did not improve from 0.99310\n","Epoch 3/5\n","49/49 [==============================] - 413s 8s/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 0.0249 - val_accuracy: 0.9904\n","\n","Epoch 00003: val_accuracy did not improve from 0.99310\n","Epoch 4/5\n","49/49 [==============================] - 411s 8s/step - loss: 0.0121 - accuracy: 0.9953 - val_loss: 0.0225 - val_accuracy: 0.9911\n","\n","Epoch 00004: val_accuracy did not improve from 0.99310\n","Epoch 5/5\n","49/49 [==============================] - 413s 8s/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.0194 - val_accuracy: 0.9930\n","\n","Epoch 00005: val_accuracy did not improve from 0.99310\n"]}]},{"cell_type":"code","metadata":{"id":"9gC0Vb_DmLHY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632727692878,"user_tz":-540,"elapsed":2060750,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"ae9ca55b-1cab-4e11-a4b3-62265a6906ff"},"source":["num_epochs = 5\n","\n","history = model.fit(train_input, labels, epochs=num_epochs, batch_size=4096, verbose=1, validation_split=0.2, callbacks=[es, mc])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","49/49 [==============================] - 412s 8s/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.0201 - val_accuracy: 0.9916\n","\n","Epoch 00001: val_accuracy did not improve from 0.99310\n","Epoch 2/5\n","49/49 [==============================] - 412s 8s/step - loss: 0.0111 - accuracy: 0.9956 - val_loss: 0.0217 - val_accuracy: 0.9901\n","\n","Epoch 00002: val_accuracy did not improve from 0.99310\n","Epoch 3/5\n","49/49 [==============================] - 411s 8s/step - loss: 0.0111 - accuracy: 0.9956 - val_loss: 0.0237 - val_accuracy: 0.9904\n","\n","Epoch 00003: val_accuracy did not improve from 0.99310\n","Epoch 4/5\n","49/49 [==============================] - 412s 8s/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.0208 - val_accuracy: 0.9913\n","\n","Epoch 00004: val_accuracy did not improve from 0.99310\n","Epoch 5/5\n","49/49 [==============================] - 413s 8s/step - loss: 0.0108 - accuracy: 0.9957 - val_loss: 0.0234 - val_accuracy: 0.9905\n","\n","Epoch 00005: val_accuracy did not improve from 0.99310\n"]}]},{"cell_type":"code","metadata":{"id":"psaxxjS3mMBh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632729755675,"user_tz":-540,"elapsed":2062808,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"08bcc753-78c8-43db-d536-81e238c20083"},"source":["num_epochs = 5\n","\n","history = model.fit(train_input, labels, epochs=num_epochs, batch_size=4096, verbose=1, validation_split=0.2, callbacks=[es, mc])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","49/49 [==============================] - 411s 8s/step - loss: 0.0108 - accuracy: 0.9957 - val_loss: 0.0202 - val_accuracy: 0.9923\n","\n","Epoch 00001: val_accuracy did not improve from 0.99310\n","Epoch 2/5\n","49/49 [==============================] - 412s 8s/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.0257 - val_accuracy: 0.9889\n","\n","Epoch 00002: val_accuracy did not improve from 0.99310\n","Epoch 3/5\n","49/49 [==============================] - 414s 8s/step - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.0225 - val_accuracy: 0.9910\n","\n","Epoch 00003: val_accuracy did not improve from 0.99310\n","Epoch 4/5\n","49/49 [==============================] - 415s 8s/step - loss: 0.0104 - accuracy: 0.9958 - val_loss: 0.0233 - val_accuracy: 0.9904\n","\n","Epoch 00004: val_accuracy did not improve from 0.99310\n","Epoch 5/5\n","49/49 [==============================] - 411s 8s/step - loss: 0.0104 - accuracy: 0.9958 - val_loss: 0.0199 - val_accuracy: 0.9920\n","\n","Epoch 00005: val_accuracy did not improve from 0.99310\n"]}]},{"cell_type":"code","metadata":{"id":"MgjOPoGnmM8c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632731816344,"user_tz":-540,"elapsed":2060680,"user":{"displayName":"MunAJung","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy4ICRmv6jTMkEHJnBIMuHFc78gkSxWStuA68=s64","userId":"09863746772758481190"}},"outputId":"e838f271-a58d-4ff6-c551-971a721424a5"},"source":["num_epochs = 5\n","\n","history = model.fit(train_input, labels, epochs=num_epochs, batch_size=4096, verbose=1, validation_split=0.2, callbacks=[es, mc])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","49/49 [==============================] - 412s 8s/step - loss: 0.0106 - accuracy: 0.9957 - val_loss: 0.0183 - val_accuracy: 0.9928\n","\n","Epoch 00001: val_accuracy did not improve from 0.99310\n","Epoch 2/5\n","49/49 [==============================] - 413s 8s/step - loss: 0.0108 - accuracy: 0.9956 - val_loss: 0.0201 - val_accuracy: 0.9918\n","\n","Epoch 00002: val_accuracy did not improve from 0.99310\n","Epoch 3/5\n","49/49 [==============================] - 413s 8s/step - loss: 0.0101 - accuracy: 0.9959 - val_loss: 0.0201 - val_accuracy: 0.9927\n","\n","Epoch 00003: val_accuracy did not improve from 0.99310\n","Epoch 4/5\n","49/49 [==============================] - 411s 8s/step - loss: 0.0100 - accuracy: 0.9960 - val_loss: 0.0241 - val_accuracy: 0.9902\n","\n","Epoch 00004: val_accuracy did not improve from 0.99310\n","Epoch 5/5\n","49/49 [==============================] - 412s 8s/step - loss: 0.0099 - accuracy: 0.9959 - val_loss: 0.0255 - val_accuracy: 0.9891\n","\n","Epoch 00005: val_accuracy did not improve from 0.99310\n"]}]},{"cell_type":"code","metadata":{"id":"pePupOhCmNv6"},"source":["model.load_weights('best_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wKaiyUWomOh5"},"source":["sample_submission=pd.read_csv('sample_submission.csv')\n","\n","# 제출 파일 작성\n","pred=model.predict(test_input)\n","pred=tf.argmax(pred, axis=1)\n","sample_submission['label']=pred\n","sample_submission.to_csv('convolutional_submission.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pv8SNf7LmPNo"},"source":[""],"execution_count":null,"outputs":[]}]}